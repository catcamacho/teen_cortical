{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from nipype.pipeline.engine import Workflow, Node, MapNode\n",
    "from nipype.interfaces.utility import IdentityInterface, Function\n",
    "from nipype.interfaces.io import SelectFiles, DataSink, FreeSurferSource\n",
    "from nipype.interfaces.fsl.preprocess import FAST\n",
    "from nipype.interfaces.fsl.utils import Reorient2Std\n",
    "from nipype.interfaces.freesurfer import FSCommand, MRIConvert\n",
    "\n",
    "# Set up study specific variables\n",
    "#project_home = '/Volumes/iang/active/ELS/ELS_FreeSurfer/Analysis'\n",
    "#project_home = '/Users/myelin/Dropbox/data/fs_practice'\n",
    "project_home = '/Users/catcamacho/Dropbox/Projects/AC_ELS_Cortex/proc/fs_practice'\n",
    "\n",
    "#fs_subjdir = '/Volumes/iang/active/ELS/ELS_FreeSurfer/ELS_FS_subjDir'\n",
    "#fs_subjdir = '/Users/myelin/Dropbox/data/fs_practice/ELS_FS_subjDir'\n",
    "fs_subjdir = '/Users/catcamacho/Dropbox/Projects/AC_ELS_Cortex/proc/fs_practice/ELS_FS_subjDir'\n",
    "\n",
    "workflow_dir = project_home + '/workflows'\n",
    "subj_proc = project_home + '/proc/subject'\n",
    "group_proc = project_home + '/proc/group'\n",
    "template_proc = project_home + '/proc/template'\n",
    "subject_info = project_home + '/misc/subjects.csv' \n",
    "template_sub = ['011-T1']\n",
    "\n",
    "#set default FreeSurfer subjects dir\n",
    "FSCommand.set_default_subjects_dir(fs_subjdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######### File handling #########\n",
    "\n",
    "#Pass in list to freesurfer source node (subs) \n",
    "fs_source = MapNode(FreeSurferSource(subjects_dir = fs_subjdir), \n",
    "                    name = 'fs_source', iterfield = ['subject_id'])\n",
    "fs_source.inputs.subject_id = template_sub\n",
    "\n",
    "#set up datasink\n",
    "datasink = Node(DataSink(base_directory = template_proc),\n",
    "                name = 'datasink')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######### Template creation functions #########\n",
    "def make3DTemplate(subject_T1s, num_proc, output_prefix):\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    \n",
    "    from os.path import abspath, split\n",
    "    from os import getcwd\n",
    "    from shutil import copyfile\n",
    "    from glob import glob\n",
    "\n",
    "    curr_dir = getcwd()\n",
    "\n",
    "    #copy T1s into current directory\n",
    "    for T1 in subject_T1s:\n",
    "        copyfile(T1,curr_dir)\n",
    "\n",
    "    # determine the common suffix across all the files in the subject_T1s list\n",
    "    T1_suffix = subject_T1s[0]\n",
    "    for a in range(0,len(subject_T1s)):\n",
    "        while T1_suffix not in subject_T1s[a]:\n",
    "            T1_suffix = T1_suffix[1:]\n",
    "    \n",
    "    # determine the common prefix across all the files in the subject_T1s list\n",
    "    (folder, T1_prefix) = split(subject_T1s[0])\n",
    "    for a in range(0,len(subject_T1s)):\n",
    "        while T1_prefix not in subject_T1s[a]:\n",
    "            T1_prefix = T1_prefix[:-1]\n",
    "\n",
    "    # -c flag is control for local computing (2= use localhost; required for -j flag)\n",
    "    # -j flag is for number of processors allowed\n",
    "    call(['antsMultivariateTemplateConstruction2.sh –d 3 –o %s –r 1 –c 2 –j %d %s*%s' % (output_prefix, num_proc, T1_prefix, T1_suffix)])\n",
    "    \n",
    "    sample_template = abspath(output_prefix + 'template0.nii.gz')\n",
    "    \n",
    "    return(sample_template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######### Template creation nodes #########\n",
    "\n",
    "#convert freesurfer brainmask files to .nii\n",
    "convertT1 = MapNode(MRIConvert(out_file='brainmask.nii.gz',\n",
    "                               out_type='niigz'), \n",
    "                    name='convertT1', \n",
    "                    iterfield = ['in_file'])\n",
    "\n",
    "#reorient files to standard space\n",
    "reorientT1 = MapNode(Reorient2Std(),\n",
    "                     name = 'reorientT1',\n",
    "                     iterfield = ['in_file'])\n",
    "\n",
    "#pass files into template function (normalized, pre-skull-stripping)\n",
    "makeTemplate = Node(Function(input_names=['subject_T1s','num_proc','output_prefix'],\n",
    "                             output_names=['sample_template'],\n",
    "                             function=make3DTemplate),\n",
    "                    name='makeTemplate')\n",
    "makeTemplate.inputs.num_proc=16 # feel free to change to suit what's free on SNI=VCS\n",
    "makeTemplate.inputs.output_prefix='ELS_CT_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180119-11:12:43,457 workflow INFO:\n",
      "\t Creating detailed dot file: /Users/myelin/Dropbox/data/fs_practice/workflows/template_flow/graph_detailed.dot\n",
      "180119-11:12:44,136 workflow INFO:\n",
      "\t Creating dot file: /Users/myelin/Dropbox/data/fs_practice/workflows/template_flow/graph.dot\n",
      "180119-11:12:44,667 workflow INFO:\n",
      "\t ['check', 'execution', 'logging']\n",
      "180119-11:12:44,751 workflow INFO:\n",
      "\t Running serially.\n",
      "180119-11:12:44,754 workflow INFO:\n",
      "\t Executing node fs_source in dir: /Users/myelin/Dropbox/data/fs_practice/workflows/template_flow/fs_source\n",
      "180119-11:12:44,830 workflow INFO:\n",
      "\t Executing node _fs_source0 in dir: /Users/myelin/Dropbox/data/fs_practice/workflows/template_flow/fs_source/mapflow/_fs_source0\n",
      "180119-11:12:44,882 workflow INFO:\n",
      "\t Runtime memory and threads stats unavailable\n",
      "180119-11:12:44,907 workflow INFO:\n",
      "\t Executing node convertT1 in dir: /Users/myelin/Dropbox/data/fs_practice/workflows/template_flow/convertT1\n",
      "180119-11:12:44,933 workflow INFO:\n",
      "\t Executing node reorientT1 in dir: /Users/myelin/Dropbox/data/fs_practice/workflows/template_flow/reorientT1\n",
      "180119-11:12:44,942 workflow INFO:\n",
      "\t Executing node makeTemplate in dir: /Users/myelin/Dropbox/data/fs_practice/workflows/template_flow/makeTemplate\n",
      "180119-11:12:44,948 workflow ERROR:\n",
      "\t ['Node makeTemplate failed to run on host myelin.stanford.edu.']\n",
      "180119-11:12:44,955 workflow INFO:\n",
      "\t Saving crash info to /Users/myelin/Dropbox/Github/teen_cortical/crash-20180119-111244-myelin-makeTemplate-64b9e32a-a260-440d-a04d-4b8c43e8771e.pklz\n",
      "180119-11:12:44,957 workflow INFO:\n",
      "\t Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python2.7/site-packages/nipype/pipeline/plugins/linear.py\", line 39, in run\n",
      "    node.run(updatehash=updatehash)\n",
      "  File \"/usr/local/lib/python2.7/site-packages/nipype/pipeline/engine/nodes.py\", line 389, in run\n",
      "    self.write_report(report_type='preexec', cwd=outdir)\n",
      "  File \"/usr/local/lib/python2.7/site-packages/nipype/pipeline/engine/nodes.py\", line 723, in write_report\n",
      "    fp.writelines(write_rst_dict(self.inputs.get()))\n",
      "  File \"/usr/local/lib/python2.7/site-packages/nipype/utils/filemanip.py\", line 474, in write_rst_dict\n",
      "    out.append(prefix + '* ' + key + ' : ' + str(value))\n",
      "UnicodeEncodeError: 'ascii' codec can't encode character u'\\u2013' in position 1086: ordinal not in range(128)\n",
      "\n",
      "180119-11:12:44,964 workflow INFO:\n",
      "\t ***********************************\n",
      "180119-11:12:44,966 workflow ERROR:\n",
      "\t could not run node: template_flow.makeTemplate\n",
      "180119-11:12:44,967 workflow INFO:\n",
      "\t crashfile: /Users/myelin/Dropbox/Github/teen_cortical/crash-20180119-111244-myelin-makeTemplate-64b9e32a-a260-440d-a04d-4b8c43e8771e.pklz\n",
      "180119-11:12:44,968 workflow INFO:\n",
      "\t ***********************************\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Workflow did not execute cleanly. Check log for details",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b53b3d398a34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtemplate_flow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mworkflow_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtemplate_flow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph2use\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'flat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtemplate_flow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/nipype/pipeline/engine/workflows.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, plugin, plugin_args, updatehash)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstr2bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'execution'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'create_report'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write_report_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdatehash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdatehash\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m         \u001b[0mdatestr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutcnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%Y%m%dT%H%M%S'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstr2bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'execution'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'write_provenance'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/nipype/pipeline/plugins/linear.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, graph, config, updatehash)\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_callback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'exception'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mreport_nodes_not_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnotrun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/nipype/pipeline/plugins/base.pyc\u001b[0m in \u001b[0;36mreport_nodes_not_run\u001b[0;34m(notrun)\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"***********************************\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         raise RuntimeError(('Workflow did not execute cleanly. '\n\u001b[0m\u001b[1;32m     96\u001b[0m                             'Check log for details'))\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Workflow did not execute cleanly. Check log for details"
     ]
    }
   ],
   "source": [
    "######### Template creation workflow #########\n",
    "template_flow = Workflow(name = \"template_flow\")\n",
    "template_flow.connect([(fs_source, convertT1, [('T1','in_file')]),\n",
    "                       (convertT1, reorientT1, [('out_file', 'in_file')]),\n",
    "                       (reorientT1, makeTemplate, [('out_file', 'subject_T1s')]),\n",
    "                       (makeTemplate, datasink, [('sample_template', 'sample_template')])\n",
    "                      ])\n",
    "\n",
    "template_flow.base_dir = workflow_dir\n",
    "template_flow.write_graph(graph2use = 'flat')\n",
    "template_flow.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######### Tissue creation nodes: segment template subjects to 5 tissue classes #########\n",
    "### 1)CSF, 2)cortical gray matter, 3)white matter, 4)subcortical gray matter, and 5)whole brain\n",
    "\n",
    "#convert freesurfer brainmask files to .nii\n",
    "convert_to_nii = MapNode(MRIConvert(out_file='brainmask.nii.gz',\n",
    "                                    out_type='niigz'), \n",
    "                         name='convert_to_nii', \n",
    "                         iterfield = ['in_file'])\n",
    "\n",
    "#reorient files for safety :)\n",
    "reorient_to_std = MapNode(Reorient2Std(),\n",
    "                         name = 'reorient_to_std',\n",
    "                         iterfield = ['in_file'])\n",
    "\n",
    "\n",
    "#brainmask gets run through segmentation (2) ---> results in segmentation into 3 tissue classes (wm, gm, csf)\n",
    "segment = MapNode(FAST(number_classes = 3, \n",
    "                       segments=True, \n",
    "                       no_bias=True), \n",
    "                  name = 'segment', \n",
    "                  iterfield = ['in_files'])\n",
    "\n",
    "# Convert freesurfer aseg to nii\n",
    "convert_aseg = MapNode(MRIConvert(out_file='aseg.nii',\n",
    "                                    out_type='niigz'), \n",
    "                         name='convert_aseg', \n",
    "                         iterfield = ['in_file'])\n",
    "\n",
    "# Reorient aseg to standard\n",
    "reorient_aseg = MapNode(Reorient2Std(),\n",
    "                         name = 'reorient_aseg',\n",
    "                         iterfield = ['in_file'])\n",
    "\n",
    "# Create subcortical and cortical gray matter masks <-- custom function\n",
    "\n",
    "\n",
    "# make brainmask based on tissue segmentation (sc gm + cortical gm + wm) <-- custom function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "######### Tissue segmentation workflow #########\n",
    "segment_flow = Workflow(name = \"segment_flow\")\n",
    "segment_flow.connect([(fs_source, convert_to_nii, [('brainmask','in_file')]),\n",
    "                      (convert_to_nii, reorient_to_std, [('out_file', 'in_file')]),\n",
    "                      (reorient_to_std, segment, [('out_file', 'in_files')]),\n",
    "                      (segment, convert_aseg, [('tissue_class_files', 'in_file')]),\n",
    "                      (convert_aseg, reorient_aseg, [('out_file', 'in_file')]),\n",
    "                      (reorient_aseg, datasink, [('out_file', 'tissue_class_files')]),\n",
    "                      #(segment, datasink, [('tissue_class_files', 'tissue_class_files')])\n",
    "                     ])\n",
    "\n",
    "segment_flow.base_dir = workflow_dir\n",
    "segment_flow.write_graph(graph2use = 'flat')\n",
    "segment_flow.run('MultiProc', plugin_args={'n_procs': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######### Tissue priors Nodes #########\n",
    "# brainmask gets registered to template (1) ---> ---> FLIRT (fsl)-results in registration matrix and registered brainmask.nii\n",
    "\n",
    "\n",
    "#apply transformation from registered brainmask to tissue segmentations ---> FLIRT (fsl)\n",
    "\n",
    "\n",
    "#average each of the tissue classes together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######### Tissue priors workflow #########\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######### Cortical thickness functions #########\n",
    "\n",
    "cmd = 'antsCorticalThickness.sh -d 3 -a t1.nii.gz -e Template.nii.gz -m brainmask.nii.gz -p segmentationPriors%d.nii.gz -o subject'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######### Cortical thickness nodes #########\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######### Cortical thickness workflow #########"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
