{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from nipype.pipeline.engine import Workflow, Node, MapNode\n",
    "from nipype.interfaces.utility import IdentityInterface, Function\n",
    "from nipype.interfaces.io import SelectFiles, DataSink, FreeSurferSource\n",
    "from nipype.interfaces.fsl.preprocess import FAST\n",
    "from nipype.interfaces.fsl.utils import Reorient2Std\n",
    "from nipype.interfaces.freesurfer import FSCommand, MRIConvert\n",
    "\n",
    "# Set up study specific variables\n",
    "#project_home = '/Volumes/iang/active/ELS/ELS_FreeSurfer/Analysis'\n",
    "#project_home = '/Users/myelin/Dropbox/data/fs_practice'\n",
    "project_home = '/Users/lucindasisk/Dropbox/Projects/AC_ELS_Cortex/proc/fs_practice'\n",
    "#project_home = '/Users/catcamacho/Dropbox/Projects/AC_ELS_Cortex/proc/fs_practice'\n",
    "\n",
    "#fs_subjdir = '/Volumes/iang/active/ELS/ELS_FreeSurfer/ELS_FS_subjDir'\n",
    "#fs_subjdir = '/Users/myelin/Dropbox/data/fs_practice/ELS_FS_subjDir'\n",
    "#fs_subjdir = '/Users/catcamacho/Dropbox/Projects/AC_ELS_Cortex/proc/fs_practice/ELS_FS_subjDir'\n",
    "fs_subjdir = '/Users/lucindasisk/Dropbox/Projects/AC_ELS_Cortex/proc/fs_practice/ELS_FS_subjDir'\n",
    "\n",
    "workflow_dir = project_home + '/workflows'\n",
    "subj_proc = project_home + '/proc/subject'\n",
    "group_proc = project_home + '/proc/group'\n",
    "template_proc = project_home + '/proc/template'\n",
    "subject_info = project_home + '/misc/subjects.csv' \n",
    "template_sub = ['011-T1']\n",
    "\n",
    "#set default FreeSurfer subjects dir\n",
    "FSCommand.set_default_subjects_dir(fs_subjdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######### File handling #########\n",
    "\n",
    "#Pass in list to freesurfer source node (subs) \n",
    "fs_source = MapNode(FreeSurferSource(subjects_dir = fs_subjdir), \n",
    "                    name = 'fs_source', iterfield = ['subject_id'])\n",
    "fs_source.inputs.subject_id = template_sub\n",
    "\n",
    "#set up datasink\n",
    "datasink = Node(DataSink(base_directory = template_proc),\n",
    "                name = 'datasink')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######### Template creation functions #########\n",
    "def make3DTemplate(subject_T1s, num_proc, output_prefix):\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    \n",
    "    from os.path import abspath, split\n",
    "    from os import getcwd\n",
    "    from shutil import copyfile\n",
    "    from glob import glob\n",
    "\n",
    "    curr_dir = getcwd()\n",
    "\n",
    "    #copy T1s into current directory\n",
    "    for T1 in subject_T1s:\n",
    "        copyfile(T1,curr_dir)\n",
    "\n",
    "    # determine the common suffix across all the files in the subject_T1s list\n",
    "    T1_suffix = subject_T1s[0]\n",
    "    for a in range(0,len(subject_T1s)):\n",
    "        while T1_suffix not in subject_T1s[a]:\n",
    "            T1_suffix = T1_suffix[1:]\n",
    "    \n",
    "    # determine the common prefix across all the files in the subject_T1s list\n",
    "    (folder, T1_prefix) = split(subject_T1s[0])\n",
    "    for a in range(0,len(subject_T1s)):\n",
    "        while T1_prefix not in subject_T1s[a]:\n",
    "            T1_prefix = T1_prefix[:-1]\n",
    "\n",
    "    # -c flag is control for local computing (2= use localhost; required for -j flag)\n",
    "    # -j flag is for number of processors allowed\n",
    "    call(['antsMultivariateTemplateConstruction2.sh –d 3 –o %s –r 1 –c 2 –j %d %s*%s' % (output_prefix, num_proc, T1_prefix, T1_suffix)])\n",
    "    \n",
    "    sample_template = abspath(output_prefix + 'template0.nii.gz')\n",
    "    \n",
    "    return(sample_template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######### Template creation nodes #########\n",
    "\n",
    "#convert freesurfer brainmask files to .nii\n",
    "convertT1 = MapNode(MRIConvert(out_file='brainmask.nii.gz',\n",
    "                               out_type='niigz'), \n",
    "                    name='convertT1', \n",
    "                    iterfield = ['in_file'])\n",
    "\n",
    "#reorient files to standard space\n",
    "reorientT1 = MapNode(Reorient2Std(),\n",
    "                     name = 'reorientT1',\n",
    "                     iterfield = ['in_file'])\n",
    "\n",
    "#pass files into template function (normalized, pre-skull-stripping)\n",
    "makeTemplate = Node(Function(input_names=['subject_T1s','num_proc','output_prefix'],\n",
    "                             output_names=['sample_template'],\n",
    "                             function=make3DTemplate),\n",
    "                    name='makeTemplate')\n",
    "makeTemplate.inputs.num_proc=16 # feel free to change to suit what's free on SNI=VCS\n",
    "makeTemplate.inputs.output_prefix='ELS_CT_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######### Template creation workflow #########\n",
    "template_flow = Workflow(name = \"template_flow\")\n",
    "template_flow.connect([(fs_source, convertT1, [('T1','in_file')]),\n",
    "                       (convertT1, reorientT1, [('out_file', 'in_file')]),\n",
    "                       (reorientT1, makeTemplate, [('out_file', 'subject_T1s')]),\n",
    "                       (makeTemplate, datasink, [('sample_template', 'sample_template')])\n",
    "                      ])\n",
    "\n",
    "template_flow.base_dir = workflow_dir\n",
    "template_flow.write_graph(graph2use = 'flat')\n",
    "template_flow.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "######### Tissue creation nodes: segment template subjects to 5 tissue classes #########\n",
    "### 1)CSF, 2)cortical gray matter, 3)white matter, 4)subcortical gray matter, and 5)whole brain\n",
    "\n",
    "#convert freesurfer brainmask files to .nii\n",
    "convert_to_nii = MapNode(MRIConvert(out_file='brainmask.nii.gz',\n",
    "                                    out_type='niigz'), \n",
    "                         name='convert_to_nii', \n",
    "                         iterfield = ['in_file'])\n",
    "\n",
    "#reorient files for safety :)\n",
    "reorient_to_std = MapNode(Reorient2Std(),\n",
    "                         name = 'reorient_to_std',\n",
    "                         iterfield = ['in_file'])\n",
    "\n",
    "\n",
    "#brainmask gets run through segmentation (2) ---> results in segmentation into 3 tissue classes (wm, gm, csf)\n",
    "segment = MapNode(FAST(number_classes = 3, \n",
    "                       segments=True, \n",
    "                       no_bias=True), \n",
    "                  name = 'segment', \n",
    "                  iterfield = ['in_files'])\n",
    "\n",
    "# Convert freesurfer aseg to nii\n",
    "convert_aseg = MapNode(MRIConvert(out_file='aseg.nii',\n",
    "                                    out_type='niigz'), \n",
    "                         name='convert_aseg', \n",
    "                         iterfield = ['in_file'])\n",
    "\n",
    "# Reorient aseg to standard\n",
    "reorient_aseg = MapNode(Reorient2Std(),\n",
    "                         name = 'reorient_aseg',\n",
    "                         iterfield = ['in_file'])\n",
    "\n",
    "# Create subcortical and cortical gray matter masks <-- custom function. inputs: fs aseg + tissue class files\n",
    "def aseg_to_tissuemaps(aseg):\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from nibabel import load, save, Nifti1Image\n",
    "    from numpy import zeros_like\n",
    "    from os.path import abspath\n",
    "    aseg_nifti = load(aseg)\n",
    "    aseg_data = aseg_nifti.get_data()\n",
    "    cortical_labels = [3, 42]\n",
    "    subcortical_labels =[10, 11, 12, 13, 17, 18, 26, 49, 50, 51, 52, 53, 54, 58]\n",
    "\n",
    "    #creating array of zeroes that replaces 0's with 1's when matches values of subcortical_labels\n",
    "    cortical_data = aseg_data\n",
    "    temp2 = zeros_like(cortical_data)\n",
    "    for x in cortical_labels:\n",
    "        temp2[cortical_data == x] = 1\n",
    "    subcort_data = aseg_data\n",
    "    temp = zeros_like(subcort_data) \n",
    "    for x in subcortical_labels:\n",
    "        temp[subcort_data == x] = 1\n",
    "    \n",
    "    subcort_data = temp\n",
    "    cortical_data = temp2\n",
    "    subcort_nifti = Nifti1Image(subcort_data, aseg_nifti.affine)\n",
    "    cortical_nifti = Nifti1Image(cortical_data, aseg_nifti.affine)\n",
    "    save(subcort_nifti, \"subcortical_gm.nii\")\n",
    "    save(cortical_nifti, \"cortical_gm.nii\")\n",
    "    subcort_file = abspath(\"subcortical_gm.nii\")\n",
    "    cortical_file = abspath(\"cortical_gm.nii\")\n",
    "    gm_list = [subcort_file, cortical_file]\n",
    "    return(gm_list)\n",
    "\n",
    "aseg_to_gm = Node(Function(input_names=['aseg'],\n",
    "                           output_names=['gm_list'],\n",
    "                           function=aseg_to_tissuemaps),\n",
    "                  name='aseg_to_gm')\n",
    "\n",
    "def relabel_fast(fast_tissue_list):\n",
    "    from nipype import config, logging\n",
    "    from os.path import split\n",
    "    from os import rename\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    tissue_list = fast_tissue_list.sorted()\n",
    "    csf = tissue_list[0]\n",
    "    wm = tissue_list[2]\n",
    "    [wd, csf_file] = split(csf)\n",
    "    [wd, wm_file] = split(wm)\n",
    "    rename(csf, wd + 'csf.nii.gz')\n",
    "    rename(wm, wd + 'wm.nii.gz')\n",
    "    wm_csf = [wd + 'csf.nii.gz', wd + 'wm.nii.gz']\n",
    "    return(wm_csf)\n",
    "\n",
    "relabel_fast_seg = Node(Function(input_names=['fast_tissue_list'],\n",
    "                                 output_names=['wm_csf'],\n",
    "                                 function=relabel_fast),\n",
    "                        name='relabel_fast_seg')\n",
    "\n",
    "# make brainmask based on tissue segmentation (sc gm + cortical gm + wm) <-- custom function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3ff77fbedf9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m                       \u001b[0;34m(\u001b[0m\u001b[0maseg_to_tissuemaps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasink\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'aseg_to_gm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gm_files'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                       \u001b[0;31m#below file makes an error - maybe because we already referenced datasink?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                       \u001b[0;34m(\u001b[0m\u001b[0mrelabel_fast_seg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasink\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wm_csf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wm_csf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                       \u001b[0;31m#(segment, datasink, [('tissue_class_files', 'tissue_class_files')])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/nipype/pipeline/engine/workflows.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0mnewnodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewnodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnewnodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hierarchy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/nipype/pipeline/engine/workflows.py\u001b[0m in \u001b[0;36m_check_nodes\u001b[0;34m(self, nodes)\u001b[0m\n\u001b[1;32m    708\u001b[0m         \u001b[0mnode_lineage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hierarchy\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m                 \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'name'"
     ]
    }
   ],
   "source": [
    "######### Tissue segmentation workflow #########\n",
    "segment_flow = Workflow(name = \"segment_flow\")\n",
    "segment_flow.connect([(fs_source, convert_to_nii, [('brainmask','in_file')]),\n",
    "                      (convert_to_nii, reorient_to_std, [('out_file', 'in_file')]),\n",
    "                      (reorient_to_std, segment, [('out_file', 'in_files')]),\n",
    "                      (segment, convert_aseg, [('tissue_class_files', 'in_file')]),\n",
    "                      (convert_aseg, reorient_aseg, [('out_file', 'in_file')]),\n",
    "                      (reorient_aseg, aseg_to_tissuemaps, [('out_file', 'aseg')]),\n",
    "                      (reorient_aseg, relabel_fast_seg, [('out_file', 'fast_tissue_list')]),\n",
    "                      (aseg_to_tissuemaps, datasink, [('aseg_to_gm', 'gm_files')]),\n",
    "                      #below file makes an error - maybe because we already referenced datasink?\n",
    "                      (relabel_fast_seg, datasink, [('wm_csf', 'wm_csf')])\n",
    "                      \n",
    "                      #(segment, datasink, [('tissue_class_files', 'tissue_class_files')])\n",
    "                     ])\n",
    "\n",
    "segment_flow.base_dir = workflow_dir\n",
    "segment_flow.write_graph(graph2use = 'flat')\n",
    "segment_flow.run('MultiProc', plugin_args={'n_procs': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######### Tissue priors Nodes #########\n",
    "# brainmask gets registered to template (1) ---> ---> FLIRT (fsl)-results in registration matrix and registered brainmask.nii\n",
    "\n",
    "\n",
    "#apply transformation from registered brainmask to tissue segmentations ---> FLIRT (fsl)\n",
    "\n",
    "\n",
    "#average each of the tissue classes together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######### Tissue priors workflow #########\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######### Cortical thickness functions #########\n",
    "\n",
    "cmd = 'antsCorticalThickness.sh -d 3 -a t1.nii.gz -e Template.nii.gz -m brainmask.nii.gz -p segmentationPriors%d.nii.gz -o subject'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######### Cortical thickness nodes #########\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######### Cortical thickness workflow #########"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
